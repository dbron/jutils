NB. Neural-network test
require 'colib'
require 'plot'
load 'd:\trade\neuralnet.ijs'
load 'd:\trade\neurallayer.ijs'


NB. Create the test function (the values are saved below)
NB. test function is the rational function:
NB. (x^2 + y^2 - 3xy + 4x - y) / (1.5x^2 - y^2 - 2xy +y + 1)
poly2 =: 4 : '+/ , x. * *// y. ^"0 1 (0 1 2)'"2 1
p2 =: 3 3 $ 0.7 _2 4 _2  _1 0 3.5 0 0
p1 =: 3 3 $ 6 _10 10  _10 _4 0  12 0 0
testfun =: (p1&poly2) % (p2&poly2)
NB. Generate 100 random samples, plus a little noise (noise _0.1 to 0.1).  Range is 0-1
testxy =: (%~ ?@:(100 2&$)) 1000000
testresults =: ,"0 (] + _0.1"_ + 500"_ %~ [: ? 100"0) testfun testxy
txy =: ".;._2  (0 : 0)
0.379555 0.194818
0.319194 0.709209
0.675875 0.445181
0.170775  0.21941
0.624856 0.958394
0.732063 0.797076
0.466221 0.780945
0.357213 0.686897
0.684745 0.513958
 0.10616 0.235205
  0.1011 0.201711
0.164463 0.131667
0.939764 0.629951
0.599269 0.921825
0.129359 0.151707
0.749655 0.463282
0.386553 0.808736
0.440244 0.197439
0.369358 0.810589
0.583872 0.148553
0.740075 0.453555
0.907051 0.817892
 0.32227 0.398683
0.680725 0.952567
0.809267 0.356381
0.701817 0.443432
0.762832 0.929723
0.868863 0.989785
0.330194 0.582326
0.156742 0.379536
0.864647 0.134526
0.987481  0.60276
0.593737 0.939581
0.548185 0.359045
0.480921 0.842862
0.994933 0.847732
0.845889 0.863586
0.300899 0.222689
0.734892 0.342778
0.079147 0.227626
0.720907 0.284046
0.974035 0.615361
0.387341 0.054929
0.198979 0.250097
 0.38684 0.622047
0.758406 0.537853
0.704293 0.054805
0.110974  0.15206
0.687326 0.894701
 0.25437 0.197573
0.624088 0.058127
0.943565 0.499659
 0.78457 0.281381
0.178715 0.669634
0.541013 0.813847
0.328237 0.692862
 0.93969 0.373991
0.678103  0.89093
0.873489 0.730982
0.617352 0.837361
 0.53452 0.680121
 0.79369 0.551048
0.468801 0.153776
0.520719 0.732284
0.512449 0.742697
0.517524  0.04109
0.613677 0.084474
0.769391 0.158875
0.221466 0.186126
0.225447 0.101693
  0.1556 0.184935
0.204648  0.52355
0.313182 0.650808
0.146512 0.430861
0.492506 0.562429
0.745517 0.905204
0.774536 0.633298
0.843354  0.26325
0.443234 0.445023
0.509809 0.371441
0.815309  0.91354
0.871343 0.673725
0.296708  0.77721
0.579229 0.102277
0.978398 0.947455
0.888482 0.717626
0.145185 0.135977
0.373876 0.748355
0.618508 0.269195
0.367953 0.199623
0.070788   0.7435
0.006882 0.678903
0.323696 0.361555
0.658915 0.395328
0.286992 0.477096
0.566026 0.213892
0.899316 0.816671
0.793969 0.252669
0.611188 0.250637
0.459621 0.855255
)
tr =: ,@:".;._2  (0 : 0)
 15.4687
  1.3274
 1.88904
 15.6702
0.921579
0.785545
0.743775
 1.10276
 1.26696
 12.6036
 12.6175
 13.7046
  1.5726
0.823155
 13.0868
 1.81514
 1.06094
 11.4885
 1.05398
  6.1564
 1.82604
 1.16457
 8.66288
0.892656
 2.67558
 1.97172
0.877833
 1.06031
 1.87763
  9.1773
 3.63643
 1.66219
0.831576
 4.08313
0.841947
 1.21248
 1.00079
 20.5649
 2.82803
 11.5079
 3.44026
 1.70113
 10.0734
 17.1697
 1.16814
 1.47446
 4.73963
 12.5968
 0.76863
 19.0373
 5.44701
 1.89074
 3.12042
 2.37851
 0.67095
 1.41278
 2.59968
0.696049
  1.2086
0.739058
0.564898
  1.3875
 9.57644
0.528636
0.732907
  6.9575
 5.72968
 4.03905
 17.4558
 13.7849
 14.6206
  3.9581
 1.63454
 6.90534
 1.04087
0.757188
0.979034
 3.25037
 3.29453
 4.48065
0.978183
 1.14352
 1.38638
 6.20785
 1.22783
 1.18413
 13.2842
 1.07641
 4.55877
 16.4201
 2.55291
 3.17337
 12.1159
 2.51211
 4.55503
 6.20118
 1.19257
  3.4651
 4.86466
0.824668
)

NB. Do the same, but create the validation set, with 50 points
cvecxy =: (%~ ?@:(50 2&$)) 1000000
cvecresults =: ,"0 (] + _0.1"_ + 500"_ %~ [: ? 100"0) testfun cvecxy
cvxy =: ".;._2  (0 : 0)
0.834732 0.354524
0.498372 0.149003
0.300638 0.823799
0.605689 0.815385
0.185998 0.074166
0.520639 0.387057
0.271272 0.277497
0.898249 0.877255
0.032895 0.867661
0.786397 0.975454
 0.46774 0.315039
0.861751 0.454141
0.762955 0.985257
0.216617 0.682817
0.118143 0.635094
0.035358 0.271627
0.251615 0.901148
0.599057 0.355396
0.148529 0.340015
0.636438 0.629797
0.999099 0.859395
0.861956 0.901078
0.424835  0.21489
0.659619 0.226122
0.436741 0.307235
 0.70715 0.070464
0.305003 0.187128
0.074141 0.098923
 0.60488 0.234091
0.373788 0.268428
0.480459 0.080794
0.921257 0.578864
0.983449 0.841797
0.083246 0.125041
0.570538 0.036212
0.620039 0.003205
0.873751 0.149218
0.907968  0.22111
0.210795 0.834191
0.261066 0.742329
0.325145 0.712356
 0.57065 0.927094
0.675806 0.271469
0.580225 0.844845
0.323221 0.388566
0.641849 0.563027
0.803497 0.378258
0.398302 0.263838
0.330842 0.471967
0.361316 0.647259
)
cvr =: ,@:".;._2  (0 : 0)
 2.62659
 8.42909
 1.35937
0.693326
 12.3764
 3.78992
 20.1936
 1.12776
 2.34309
 0.91318
 8.06613
 2.05914
0.990936
 2.15544
 3.04965
 9.65284
 1.45154
 3.55454
 10.9772
 0.76421
 1.35621
0.979398
 12.8606
 4.58239
 10.2791
  4.6548
 18.6537
 10.8338
 5.26974
  17.072
   8.144
  1.6873
 1.20347
 11.5125
 6.21104
 5.49201
 3.57984
 3.29937
 1.73312
 1.66451
 1.40123
0.823722
 3.87667
0.707499
   9.558
0.871628
 2.53098
 14.9462
 4.16744
 1.18527
)

NB. Simpler function: checkerboard
tfn =: (-&0.5) @: (=/) @: (0.5&<) "1
tr =: tfn txy
cvr =: tfn cvxy
ntest =: 3 : 0
9!:1 (7^5)
NB. Allocate test layers.  20 sigmoid neurons, 1 linear output
net =: (,<(3 2 $  8 2;('tanh';0.125);8 8;('tanh';0.125);1 8;<('tanh';0))) conew 'neuralnet'
((<']'),(<0.20;0 50),(<''),(<0.000002 0.00000002),(<80 100),(<0.00001),(<<'rmserr')) train__net (txy;tr);<(cvxy;cvr)
''
)
ntest2 =: 3 : 0
l1 =. 2 2;('tanh';0.125);<2 3 $ 0 0 1  1 0 1
l2 =. 2 2;('tanh';0.125);<2 3 $ 0.5 0.5 0.5   _0.5 _0.5 0.5
l3 =. 1 2;('tanh';0);<1 3 $ 0.5 0.5 0
net =: (,<(l1,l2,:l3)) conew 'neuralnet'
txy =. 2 2 $ 1 0  0 1
tr =. 2 1 $ 0 1
cvxy =. txy
cvr =. tr
((<']'),(<0.0;0 50),(<''),(<0.000002 0.00000002),(<3 3),(<1000000),(<<'rmserr')) train__net (txy;tr);<(cvxy;cvr)
)

NB. net =: (,<(3 2 $  20 2;'tanh';20 20;'tanh';1 20;'linear')) conew 'neuralnet'
NB. ((<']'),(<0.05 0.05;0 400),(<5 20),(<3 2 $0.005 40000 0.002 30000 0.002 30000),(<600),(<4 2 $0.01 0.80 0.2 0.60 0.5 0.60 1.5 0),(<<'rmserr')) train__net (txy;tr);<(cvxy;cvr)
NB.  net =: (,<(3 2 $  10 2;'tanh';10 10;'tanh';1 10;'linear')) conew 'neuralnet'
NB.  ((<']'),(<0.2 0.2;0 400),(<5 20),(<3 2 $0.002 40000 0.001 30000 0.001 30000),(<600),(<4 2 $0.01 0.80 0.2 0.60 0.5 0.60 1.5 0),(<<'rmserr')) train__net (txy;tr);<(cvxy;cvr)
NB. net =: (,<(2 2 $  40 2;'tanh';1 40;'linear')) conew 'neuralnet'
NB. ((<']'),(<0.2 0.2;0 400),(<5 20),(<2 2 $0.005 40000 0.005 40000),(<1400),(<4 2 $0.01 0.80 0.2 0.60 0.5 0.60 1.5 0 ),(<<'rmserr')) train__net (txy;tr);<(cvxy;cvr)
NB. good net =: (,<(2 2 $  40 2;'tanh';1 40;'linear')) conew 'neuralnet'
NB. good ((<']'),(<0.05 0.05;0 400),(<5 20),(<2 2 $0.007 40000 0.005 40000),(<1400),(<2 2 $ 0 0 0.1 0),(<<'rmserr')) train__net (txy;tr);<(cvxy;cvr)


